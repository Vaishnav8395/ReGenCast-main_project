{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVpqkVuqzIWI",
        "outputId": "210c0123-ccc1-44fc-ae95-99cb555ec9ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from shap) (0.61.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->shap) (0.44.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install pandas numpy scikit-learn xgboost shap matplotlib seaborn joblib\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from itertools import product\n",
        "from sklearn import metrics\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import shap\n",
        "import joblib\n",
        "import warnings\n",
        "from urllib.request import urlopen\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "\n",
        "# Define constants in a dictionary\n",
        "config = {\n",
        "    'file_path': \"https://raw.githubusercontent.com/Vaishnav8395/ReGenCast/main/SunPower_Full.csv\",\n",
        "    'target_variable': 'Active_Power',\n",
        "    'predictors': ['temperature_2m', 'relativehumidity_2m', 'direct_radiation', 'diffuse_radiation',  'windspeed_10m', 'cloudcover', 'season'],\n",
        "    'categorical_variables': ['season'],\n",
        "    'time_intervals': ['first_interval','second_interval','third_interval','fourth_interval','fifth_interval','sixth_interval'],\n",
        "    'weather_types': ['TypeA', 'TypeB', 'TypeC'],\n",
        "    'standardize_predictor_list': ['temperature_2m', 'relativehumidity_2m', 'direct_radiation', 'diffuse_radiation',  'windspeed_10m', 'cloudcover']\n",
        "}\n",
        "\n",
        "# Load data\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path, sep='\\t')\n",
        "    df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df[config['target_variable']] = df[config['target_variable']].clip(lower=0)  # Set negative values to 0\n",
        "    return df\n",
        "\n",
        "# Add season\n",
        "def add_season(df):\n",
        "    def season(month):\n",
        "        if month in [12, 1, 2]:\n",
        "            return 'winter'\n",
        "        elif month in [3, 4, 5]:\n",
        "            return 'spring'\n",
        "        elif month in [6, 7, 8]:\n",
        "            return 'summer'\n",
        "        else:\n",
        "            return 'fall'\n",
        "    df['season'] = df['date'].dt.month.apply(season)\n",
        "    return df\n",
        "\n",
        "# Choose only 7-18 interval\n",
        "def choose_interval(df):\n",
        "    df = df.sort_values('date')\n",
        "    df = df.set_index('date')\n",
        "    df = df.between_time('07:00', '18:00')\n",
        "    return df\n",
        "\n",
        "# Split data\n",
        "def split_data(df):\n",
        "    ord_enc = OrdinalEncoder()\n",
        "    season = ord_enc.fit_transform(np.array(df['season']).reshape(-1, 1))\n",
        "    df['season'] = season\n",
        "    cutoff_date = df.index.min() + pd.DateOffset(years=7)\n",
        "    train = df.loc[:cutoff_date]\n",
        "    test = df.loc[cutoff_date + pd.DateOffset(hours=1):]\n",
        "    return train, test\n",
        "\n",
        "# Detect time interval\n",
        "def detect_time_interval(df):\n",
        "    df_time_detect = df.copy()\n",
        "    intervals = {'first_interval': (7, 9), 'second_interval': (9, 11), 'third_interval': (11, 13),\n",
        "                 'fourth_interval': (13, 15), 'fifth_interval': (15, 17), 'sixth_interval': (17, 18)}\n",
        "    df_time_detect['time_interval'] = pd.cut(df_time_detect.index.hour, bins=[interval[0] for interval in intervals.values()] + [24],\n",
        "                                            labels=[interval_name for interval_name in intervals.keys()],\n",
        "                                            include_lowest=True, right=False)\n",
        "    return df_time_detect\n",
        "\n",
        "# Create weather type\n",
        "def create_weather_type(train):\n",
        "    new_train = pd.DataFrame()\n",
        "    for interval in config['time_intervals']:\n",
        "        train_df = train[train['time_interval'] == interval].copy()\n",
        "        weather_type = []\n",
        "        avg_kwh = np.mean(train_df[config['target_variable']])\n",
        "        max_kwh = max(train_df[config['target_variable']])\n",
        "        min_kwh = min(train_df[config['target_variable']])\n",
        "        for y in train_df[config['target_variable']]:\n",
        "            if y >= avg_kwh:\n",
        "                weather_type.append(\"TypeA\")\n",
        "            elif (y > avg_kwh - (avg_kwh - min_kwh) / 2) and (y < avg_kwh):\n",
        "                weather_type.append(\"TypeB\")\n",
        "            elif (y >= 0) and (y <= avg_kwh - (avg_kwh - min_kwh) / 2):\n",
        "                weather_type.append(\"TypeC\")\n",
        "            else:\n",
        "                raise ValueError(f\"Something wrong happened in weather type classification for {interval}\")\n",
        "        train_df['weather_type'] = weather_type\n",
        "        new_train = pd.concat([new_train, train_df])\n",
        "    new_train = new_train.sort_index()\n",
        "    return new_train\n",
        "\n",
        "# Train random forest classifier\n",
        "def train_rf_classifier(X_train, y_train):\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [5, 10, 20],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "    rfc = RandomForestClassifier()\n",
        "    grid_search = GridSearchCV(rfc, param_grid, cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search\n",
        "\n",
        "# Predict weather type\n",
        "def predict_weather_type(grid_search, X_test):\n",
        "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
        "    X_test.loc[:, 'weather_type'] = y_pred\n",
        "    return X_test\n",
        "\n",
        "# Classify weather type\n",
        "def classify_weather_type(new_train, test):\n",
        "    new_test = pd.DataFrame()\n",
        "    for interval in config['time_intervals']:\n",
        "        interval_train_dataset = new_train[new_train['time_interval'] == interval].copy()\n",
        "        interval_test_dataset = test[test['time_interval'] == interval].copy()\n",
        "        try:\n",
        "            grid = joblib.load(urlopen(f'https://raw.githubusercontent.com/Vaishnav8395/ReGenCast/master/ClassifiedWeatherTypes/RF_Weather_{interval}_.pkl'))\n",
        "            classified_weather_type = predict_weather_type(grid, interval_test_dataset[config['predictors']].copy())\n",
        "        except:\n",
        "            grid = train_rf_classifier(interval_train_dataset[config['predictors']], interval_train_dataset['weather_type'])\n",
        "            joblib.dump(grid, f'RF_Weather_{interval}_.pkl')  # Save fitted model\n",
        "            classified_weather_type = predict_weather_type(grid, interval_test_dataset[config['predictors']].copy())\n",
        "        classified_weather_type['time_interval'] = interval\n",
        "        print(f\"Weather type Predictions done for {interval}\")\n",
        "        new_test = pd.concat([new_test, classified_weather_type])\n",
        "    new_test = new_test.sort_index()\n",
        "    return new_test\n",
        "\n",
        "# Standardize data\n",
        "def standardize_data(new_train, new_test):\n",
        "    X_new_train = new_train[config['standardize_predictor_list']]\n",
        "    X_new_test = new_test[config['standardize_predictor_list']]\n",
        "    predictor_scaler = StandardScaler()\n",
        "    predictor_scaler_fit = predictor_scaler.fit(X_new_train)\n",
        "    X_new_train = predictor_scaler_fit.transform(X_new_train)\n",
        "    X_new_test = predictor_scaler_fit.transform(X_new_test)\n",
        "    new_stand_train = pd.DataFrame(X_new_train, index=new_train[config['standardize_predictor_list']].index, columns=new_train[config['standardize_predictor_list']].columns)\n",
        "    new_stand_test = pd.DataFrame(X_new_test, index=new_test[config['standardize_predictor_list']].index, columns=new_test[config['standardize_predictor_list']].columns)\n",
        "    new_stand_train = pd.concat([new_stand_train, new_train[['season', config['target_variable'], 'weather_type', 'time_interval']]], axis=1)\n",
        "    new_stand_test = pd.concat([new_stand_test, new_test[['season', 'weather_type', 'time_interval']]], axis=1)\n",
        "    return new_stand_train, new_stand_test\n",
        "\n",
        "# Train XGBoost regressor\n",
        "def train_XGB_regressor(X_train, y_train):\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 500],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'colsample_bytree': [0.3, 0.7]\n",
        "    }\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=XGBRegressor(verbosity=0),\n",
        "        param_grid=param_grid,\n",
        "        scoring='neg_root_mean_squared_error',\n",
        "        cv=10,\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train, verbose=0)\n",
        "    return grid_search\n",
        "\n",
        "# Train Random Forest regressor\n",
        "def train_RF_regressor(X_train, y_train):\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=RandomForestRegressor(),\n",
        "        param_grid=param_grid,\n",
        "        scoring='neg_root_mean_squared_error',\n",
        "        cv=10,\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search\n",
        "\n",
        "# Train MLP regressor\n",
        "def train_MLP_regressor(X_train, y_train):\n",
        "    param_grid = {\n",
        "        'alpha': 10.0 ** -np.arange(1, 7),  # Regularization parameter\n",
        "        'activation': ['relu'],  # Activation function\n",
        "        'learning_rate_init': [0.1, 0.01, 0.001, 0.0001]  # Learning rate\n",
        "    }\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=MLPRegressor(hidden_layer_sizes=(15, 15), solver='adam', max_iter=10000),\n",
        "        param_grid=param_grid,\n",
        "        scoring='neg_root_mean_squared_error',\n",
        "        cv=10,\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search\n",
        "\n",
        "# Train and predict MLP model\n",
        "def train_predict_MLP_model(new_stand_train, new_stand_test):\n",
        "    forecast_test = pd.DataFrame()\n",
        "    for interval, weather_type in product(config['time_intervals'], config['weather_types']):\n",
        "        X_train = new_stand_train[(new_stand_train['time_interval'] == interval) & (new_stand_train['weather_type'] == weather_type)][config['predictors']]\n",
        "        y_train = new_stand_train[(new_stand_train['time_interval'] == interval) & (new_stand_train['weather_type'] == weather_type)][config['target_variable']]\n",
        "        X_test = new_stand_test[(new_stand_test['time_interval'] == interval) & (new_stand_test['weather_type'] == weather_type)][config['predictors']]\n",
        "        try:\n",
        "            md = joblib.load(urlopen(f'https://raw.githubusercontent.com/Vaishnav8395/ReGenCast/master/Fitted_Models/MLP_fitted_{interval}_{weather_type}.pkl'))\n",
        "            predictions = md.predict(X_test)\n",
        "        except:\n",
        "            md = train_MLP_regressor(X_train, y_train)\n",
        "            joblib.dump(md, f'MLP_fitted_{interval}_{weather_type}.pkl')  # Save fitted model\n",
        "            predictions = md.predict(X_test)\n",
        "        print(f\"Energy Predictions done for {interval, weather_type}\")\n",
        "        TestingData = pd.DataFrame(data=X_test.copy(), columns=X_test.columns)\n",
        "        TestingData['PredictedTotalPower'] = predictions\n",
        "        forecast_test = pd.concat([forecast_test, TestingData])\n",
        "    forecast_test = forecast_test.sort_index()\n",
        "    return forecast_test\n",
        "\n",
        "# Train and predict XGBoost model\n",
        "def train_predict_XGB_model(new_stand_train, new_stand_test):\n",
        "    forecast_test = pd.DataFrame()\n",
        "    for interval, weather_type in product(config['time_intervals'], config['weather_types']):\n",
        "        X_train = new_stand_train[(new_stand_train['time_interval'] == interval) & (new_stand_train['weather_type'] == weather_type)][config['predictors']]\n",
        "        y_train = new_stand_train[(new_stand_train['time_interval'] == interval) & (new_stand_train['weather_type'] == weather_type)][config['target_variable']]\n",
        "        X_test = new_stand_test[(new_stand_test['time_interval'] == interval) & (new_stand_test['weather_type'] == weather_type)][config['predictors']]\n",
        "        try:\n",
        "            md = joblib.load(urlopen(f'https://raw.githubusercontent.com/Vaishnav8395/ReGenCast/master/Fitted_Models/XGB_fitted_{interval}_{weather_type}.pkl'))\n",
        "            predictions = md.predict(X_test)\n",
        "        except:\n",
        "            md = train_XGB_regressor(X_train, y_train)\n",
        "            joblib.dump(md, f'XGB_fitted_{interval}_{weather_type}.pkl')  # Save fitted model\n",
        "            predictions = md.predict(X_test)\n",
        "        print(f\"Energy Predictions done for {interval, weather_type}\")\n",
        "        TestingData = pd.DataFrame(data=X_test.copy(), columns=X_test.columns)\n",
        "        TestingData['PredictedTotalPower'] = predictions\n",
        "        forecast_test = pd.concat([forecast_test, TestingData])\n",
        "    forecast_test = forecast_test.sort_index()\n",
        "    return forecast_test\n",
        "\n",
        "# Train and predict Random Forest model\n",
        "def train_predict_RF_model(new_stand_train, new_stand_test):\n",
        "    forecast_test = pd.DataFrame()\n",
        "    for interval, weather_type in product(config['time_intervals'], config['weather_types']):\n",
        "        X_train = new_stand_train[(new_stand_train['time_interval'] == interval) & (new_stand_train['weather_type'] == weather_type)][config['predictors']]\n",
        "        y_train = new_stand_train[(new_stand_train['time_interval'] == interval) & (new_stand_train['weather_type'] == weather_type)][config['target_variable']]\n",
        "        X_test = new_stand_test[(new_stand_test['time_interval'] == interval) & (new_stand_test['weather_type'] == weather_type)][config['predictors']]\n",
        "        try:\n",
        "            md = joblib.load(urlopen(f'https://raw.githubusercontent.com/Vaishnav8395/ReGenCast/master/Fitted_Models/RF_fitted_{interval}_{weather_type}.pkl'))\n",
        "            predictions = md.predict(X_test)\n",
        "        except:\n",
        "            md = train_RF_regressor(X_train, y_train)\n",
        "            joblib.dump(md, f'RF_fitted_{interval}_{weather_type}.pkl')  # Save fitted model\n",
        "            predictions = md.predict(X_test)\n",
        "        print(f\"Energy Predictions done for {interval, weather_type}\")\n",
        "        TestingData = pd.DataFrame(data=X_test.copy(), columns=X_test.columns)\n",
        "        TestingData['PredictedTotalPower'] = predictions\n",
        "        forecast_test = pd.concat([forecast_test, TestingData])\n",
        "    forecast_test = forecast_test.sort_index()\n",
        "    return forecast_test\n",
        "\n",
        "# SMAPE\n",
        "def smape(A, F):\n",
        "    return 100 / len(A) * np.sum(np.abs(F - A) / (np.abs(A) + np.abs(F)))\n",
        "\n",
        "# Evaluate model\n",
        "def evaluate_model(forecast_test, test, new_test):\n",
        "    y_test = test.loc[new_test.index, config['target_variable']]\n",
        "    forecast_test['ActualTotalPower'] = y_test\n",
        "    # Set negative values at 0\n",
        "    forecast_test['PredictedTotalPower'] = forecast_test['PredictedTotalPower'].clip(lower=0)\n",
        "\n",
        "    mae = metrics.mean_absolute_error(forecast_test['ActualTotalPower'], forecast_test['PredictedTotalPower'])\n",
        "    mse = metrics.mean_squared_error(forecast_test['ActualTotalPower'], forecast_test['PredictedTotalPower'])\n",
        "    mape = metrics.mean_absolute_percentage_error(forecast_test['ActualTotalPower'], forecast_test['PredictedTotalPower'])\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = metrics.r2_score(forecast_test['ActualTotalPower'], forecast_test['PredictedTotalPower'])\n",
        "    smape_ = smape(forecast_test['ActualTotalPower'], forecast_test['PredictedTotalPower'])\n",
        "    print(\"Results of sklearn.metrics:\")\n",
        "    print(\"MAE:\", round(mae, 3))\n",
        "    print(\"RMSE:\", round(rmse, 3))\n",
        "    print(f\"R-Squared: {round(r2, 3) * 100} %\")\n",
        "    print(f\"Scaled mean absolute percentage error: {round(smape_, 3)} %\")\n",
        "    return mae, rmse, r2, smape_\n",
        "\n",
        "# Main order of functions\n",
        "def main():\n",
        "    df = load_data(config['file_path'])\n",
        "    df = add_season(df)\n",
        "    df = choose_interval(df)\n",
        "    train, test = split_data(df)\n",
        "    train = detect_time_interval(train)\n",
        "    test = detect_time_interval(test)\n",
        "    new_train_data = create_weather_type(train)\n",
        "    new_test_data = classify_weather_type(new_train_data, test)\n",
        "    new_stand_train, new_stand"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main order of functions\n",
        "def main():\n",
        "    # Load and preprocess data\n",
        "    df = load_data(config['file_path'])\n",
        "    df = add_season(df)\n",
        "    df = choose_interval(df)\n",
        "    train, test = split_data(df)\n",
        "    train = detect_time_interval(train)\n",
        "    test = detect_time_interval(test)\n",
        "    new_train_data = create_weather_type(train)\n",
        "    new_test_data = classify_weather_type(new_train_data, test)\n",
        "    new_stand_train, new_stand_test = standardize_data(new_train_data, new_test_data)\n",
        "\n",
        "    # Train and evaluate MLP model\n",
        "    print(\"\\nEvaluating MLP Model...\")\n",
        "    forecasted_data_MLP = train_predict_MLP_model(new_stand_train, new_stand_test)\n",
        "    mae_mlp, rmse_mlp, r2_mlp, smape_mlp = evaluate_model(forecasted_data_MLP, test, new_test_data)\n",
        "\n",
        "    # Train and evaluate XGBoost model\n",
        "    print(\"\\nEvaluating XGBoost Model...\")\n",
        "    forecasted_data_XGB = train_predict_XGB_model(new_stand_train, new_stand_test)\n",
        "    mae_xgb, rmse_xgb, r2_xgb, smape_xgb = evaluate_model(forecasted_data_XGB, test, new_test_data)\n",
        "\n",
        "    # Train and evaluate Random Forest model\n",
        "    print(\"\\nEvaluating Random Forest Model...\")\n",
        "    forecasted_data_RF = train_predict_RF_model(new_stand_train, new_stand_test)\n",
        "    mae_rf, rmse_rf, r2_rf, smape_rf = evaluate_model(forecasted_data_RF, test, new_test_data)\n",
        "\n",
        "    # Display evaluation metrics for all models\n",
        "    print(\"\\nModel Comparison:\")\n",
        "    print(\"{:<15} {:<10} {:<10} {:<10} {:<10}\".format(\"Model\", \"MAE\", \"RMSE\", \"R2\", \"SMAPE\"))\n",
        "    print(\"{:<15} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}\".format(\"MLP\", mae_mlp, rmse_mlp, r2_mlp, smape_mlp))\n",
        "    print(\"{:<15} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}\".format(\"XGBoost\", mae_xgb, rmse_xgb, r2_xgb, smape_xgb))\n",
        "    print(\"{:<15} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}\".format(\"Random Forest\", mae_rf, rmse_rf, r2_rf, smape_rf))\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTo5Bnnb0tvo",
        "outputId": "ee0193e1-c1a6-46d2-d608-54e2cbef4905"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weather type Predictions done for first_interval\n",
            "Weather type Predictions done for second_interval\n",
            "Weather type Predictions done for third_interval\n",
            "Weather type Predictions done for fourth_interval\n",
            "Weather type Predictions done for fifth_interval\n",
            "Weather type Predictions done for sixth_interval\n",
            "\n",
            "Evaluating MLP Model...\n",
            "Energy Predictions done for ('first_interval', 'TypeA')\n",
            "Energy Predictions done for ('first_interval', 'TypeB')\n",
            "Energy Predictions done for ('first_interval', 'TypeC')\n",
            "Energy Predictions done for ('second_interval', 'TypeA')\n",
            "Energy Predictions done for ('second_interval', 'TypeB')\n",
            "Energy Predictions done for ('second_interval', 'TypeC')\n",
            "Energy Predictions done for ('third_interval', 'TypeA')\n",
            "Energy Predictions done for ('third_interval', 'TypeB')\n",
            "Energy Predictions done for ('third_interval', 'TypeC')\n",
            "Energy Predictions done for ('fourth_interval', 'TypeA')\n",
            "Energy Predictions done for ('fourth_interval', 'TypeB')\n",
            "Energy Predictions done for ('fourth_interval', 'TypeC')\n",
            "Energy Predictions done for ('fifth_interval', 'TypeA')\n",
            "Energy Predictions done for ('fifth_interval', 'TypeB')\n",
            "Energy Predictions done for ('fifth_interval', 'TypeC')\n",
            "Energy Predictions done for ('sixth_interval', 'TypeA')\n",
            "Energy Predictions done for ('sixth_interval', 'TypeB')\n",
            "Energy Predictions done for ('sixth_interval', 'TypeC')\n",
            "Results of sklearn.metrics:\n",
            "MAE: 0.325\n",
            "RMSE: 0.611\n",
            "R-Squared: 85.3 %\n",
            "Scaled mean absolute percentage error: 14.679 %\n",
            "\n",
            "Evaluating XGBoost Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [18:06:58] WARNING: /workspace/src/collective/../data/../common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
            "configuration generated by an older version of XGBoost, please export the model by calling\n",
            "`Booster.save_model` from that version first, then load it back in current version. See:\n",
            "\n",
            "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
            "\n",
            "for more details about differences between saving model and serializing.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Energy Predictions done for ('first_interval', 'TypeA')\n",
            "Energy Predictions done for ('first_interval', 'TypeB')\n",
            "Energy Predictions done for ('first_interval', 'TypeC')\n",
            "Energy Predictions done for ('second_interval', 'TypeA')\n",
            "Energy Predictions done for ('second_interval', 'TypeB')\n",
            "Energy Predictions done for ('second_interval', 'TypeC')\n",
            "Energy Predictions done for ('third_interval', 'TypeA')\n",
            "Energy Predictions done for ('third_interval', 'TypeB')\n",
            "Energy Predictions done for ('third_interval', 'TypeC')\n",
            "Energy Predictions done for ('fourth_interval', 'TypeA')\n",
            "Energy Predictions done for ('fourth_interval', 'TypeB')\n",
            "Energy Predictions done for ('fourth_interval', 'TypeC')\n",
            "Energy Predictions done for ('fifth_interval', 'TypeA')\n",
            "Energy Predictions done for ('fifth_interval', 'TypeB')\n",
            "Energy Predictions done for ('fifth_interval', 'TypeC')\n",
            "Energy Predictions done for ('sixth_interval', 'TypeA')\n",
            "Energy Predictions done for ('sixth_interval', 'TypeB')\n",
            "Energy Predictions done for ('sixth_interval', 'TypeC')\n",
            "Results of sklearn.metrics:\n",
            "MAE: 0.309\n",
            "RMSE: 0.609\n",
            "R-Squared: 85.5 %\n",
            "Scaled mean absolute percentage error: 15.046 %\n",
            "\n",
            "Evaluating Random Forest Model...\n",
            "Energy Predictions done for ('first_interval', 'TypeA')\n",
            "Energy Predictions done for ('first_interval', 'TypeB')\n",
            "Energy Predictions done for ('first_interval', 'TypeC')\n",
            "Energy Predictions done for ('second_interval', 'TypeA')\n",
            "Energy Predictions done for ('second_interval', 'TypeB')\n",
            "Energy Predictions done for ('second_interval', 'TypeC')\n",
            "Energy Predictions done for ('third_interval', 'TypeA')\n",
            "Energy Predictions done for ('third_interval', 'TypeB')\n",
            "Energy Predictions done for ('third_interval', 'TypeC')\n",
            "Energy Predictions done for ('fourth_interval', 'TypeA')\n",
            "Energy Predictions done for ('fourth_interval', 'TypeB')\n",
            "Energy Predictions done for ('fourth_interval', 'TypeC')\n",
            "Energy Predictions done for ('fifth_interval', 'TypeA')\n",
            "Energy Predictions done for ('fifth_interval', 'TypeB')\n",
            "Energy Predictions done for ('fifth_interval', 'TypeC')\n",
            "Energy Predictions done for ('sixth_interval', 'TypeA')\n",
            "Energy Predictions done for ('sixth_interval', 'TypeB')\n",
            "Energy Predictions done for ('sixth_interval', 'TypeC')\n",
            "Results of sklearn.metrics:\n",
            "MAE: 0.305\n",
            "RMSE: 0.611\n",
            "R-Squared: 85.39999999999999 %\n",
            "Scaled mean absolute percentage error: 14.889 %\n",
            "\n",
            "Model Comparison:\n",
            "Model           MAE        RMSE       R2         SMAPE     \n",
            "MLP             0.325      0.611      0.853      14.679    \n",
            "XGBoost         0.309      0.609      0.855      15.046    \n",
            "Random Forest   0.305      0.611      0.854      14.889    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.2.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfCldJwn2GLx",
        "outputId": "cb0ee21b-8c59-4f75-c786-4d9daa8004a4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.5.0)\n"
          ]
        }
      ]
    }
  ]
}